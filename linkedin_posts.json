[
  {
    "author": "Paulo Rosado",
    "description": "Meus amigos e minhas amigas dev inicianteâ€¦ deixa eu te perguntar uma coisa bem sÃ©ria:\nVocÃª tÃ¡ programando, tÃ¡ aprendendo, tÃ¡ estudando â€” mas quando abre um projeto cheio de pasta, vocÃª sabe onde tÃ¡ pisando?\nSabe o que Ã© esse tal de src, controllers, services, models?\nOu vocÃª sÃ³ entra, roda o projeto e torce pra nÃ£o quebrar nada?\nPois entÃ£o vamo conversar. Vamo abrir essa caixa preta. Vamo entender de verdade.\nPorque estrutura de pastas nÃ£o Ã© frescura.\nNÃ£o Ã© enfeite.\nÃ‰ clareza. Ã‰ organizaÃ§Ã£o. Ã‰ profissionalismo.\nQuando vocÃª entende a estrutura de um projeto, vocÃª anda mais rÃ¡pido, colabora melhor, quebra menos a cabeÃ§a e ainda mostra que tÃ¡ pronto pra jogar no time de verdade.\n\"src\" Ã© onde o coraÃ§Ã£o bate.\n\"models\" Ã© onde mora a estrutura dos seus dados.\n\"services\" Ã© onde a regra do jogo acontece.\n\"controllers\" Ã© quem comanda a orquestra.\nCada pasta tem seu papel. Cada parte tem sua funÃ§Ã£o.\nE quando todo mundo respeita a estrutura, o projeto flui, a equipe cresce, e o caos vai embora.\nQuer escrever cÃ³digo limpo? Comece organizando as pastas.\nQuer crescer na carreira? Entenda o projeto que vocÃª pisa.\nQuer ser respeitado como dev? Mostre que vocÃª entende mais que sintaxe.\nOrganizaÃ§Ã£o, meu amigo, Ã© revoluÃ§Ã£o no cÃ³digo.\nEntÃ£o me diz:\nVocÃª tÃ¡ pronto pra dominar seu projeto? Ou vai continuar perdido em meio a pasta e arquivo sem saber o que faz o quÃª?",
    "image_path": "linkedin_images/post_image_0.jpg"
  },
  {
    "author": "Priyanka Vergadia",
    "description": "ğŸ›‘ ğ’ğ“ğğ ğ›ğ®ğ¢ğ¥ğğ¢ğ§ğ  ğ€ğˆ ğšğ ğğ§ğ­ğ¬ ğŸğ«ğ¨ğ¦ ğ¬ğœğ«ğšğ­ğœğ¡. Instead use this repository: 40+ production-ready agent implementations with complete source code, from basic conversational bots to enterprise multi-agent systems.\nğ–ğ¡ğšğ­ ğœğšğ®ğ ğ¡ğ­ ğ¦ğ² ğšğ­ğ­ğğ§ğ­ğ¢ğ¨ğ§:\nâ†³\nLangGraph AI\nworkflows with state management examples\nâ†³ Self-healing code agents that debug themselves\nâ†³ Multi-agent research teams using AutoGen\nâ†³ Memory-enhanced systems with episodic + semantic storage\nâ†³ Advanced RAG with controllable retrieval strategies\nğ“ğ¡ğ ğ­ğğœğ¡ğ§ğ¢ğœğšğ¥ ğğğ©ğ­ğ¡ ğ¢ğ¬ ğ¢ğ¦ğ©ğ«ğğ¬ğ¬ğ¢ğ¯ğ:\nâ†³ Vector embeddings with\nPinecone\n/\nChroma\nDB integration\nâ†³ Async processing patterns for concurrent agent execution\nâ†³\nPydantic\nmodels for structured agent outputs\nâ†³ Real-world error handling and retry mechanisms\nEach implementation includes:\nâœ… Complete notebooks with explanations\nâœ… Architecture diagrams and workflow logic\nâœ… Integration patterns for popular frameworks\nâœ… Performance optimization techniques\nThis is essentially a master class in agent engineering disguised as a GitHub repo by\nNir Diamant\n. Perfect for AI engineers who want to understand how these systems work and where to get started.\nğŸ”— Repository:\nhttps://lnkd.in/dmGE-t_6\nWhich agent architecture are you most curious about? The multi-agent collaboration patterns are fascinating.\nâ™»ï¸ If you found this useful: I regularly share Cloud & AI insights(through my newsletter subscribe\nhttps://lnkd.in/dRifnnex\n) hit follow (\nPriyanka Vergadia\n) and feel free to share it so others can learn too!\nhashtag\n#\nAIEngineering\nhashtag\n#\nLangChain\nhashtag\n#\nLangGraph\nhashtag\n#\nMultiAgent\nhashtag\n#\nMachineLearning\nhashtag\n#\nRAG\nhashtag\n#\nVectorDB\nhashtag\n#\nOpenAI\nhashtag\n#\nAi\nhashtag\n#\nAIEngineer\nhashtag\n#\nAIAgents\nhashtag\n#\nagenticai",
    "image_path": "linkedin_images/post_image_1.jpg"
  },
  {
    "author": "Pedro Lima",
    "description": "O visual importa pro usuÃ¡rio! âš¡\nOlhe para os cartÃµes e compare, qual vocÃª consegue ter mais informaÃ§Ãµes?\nClaro que essa resposta Ã© simples, MAS sÃ£o o mesmos que estÃ£o visualmente mais agradÃ¡veis, nÃ©? Essa Ã© a ideia do post, nÃ£o basta termos informaÃ§Ãµes em tela, a forma que elas sÃ£o expostas contam muito pro usuÃ¡rio, e esse detalhe nÃ£o pode ser descartado.\nNo Power BI Ã© possÃ­vel fazer de diferentes formas, como as comparadas, entÃ£o Ã© legal usarmos o melhor sempre que possÃ­vel para nossas entregas nÃ£o serem sÃ³ Ãºteis, mas agradÃ¡veis visualmente tambÃ©m. ğŸ˜\nAproveite o post que mostro os detalhes principais para vocÃª chegar ao resultado, nesse caso, usamos atÃ© DAX.\nBons estudos, Padawans! ğŸš€",
    "image_path": "linkedin_images/post_image_2.jpg"
  },
  {
    "author": "Kauan Oliveira",
    "description": "Eu sei que vocÃª ğŸ«µ jÃ¡ pesquisou algo completamente errado e mesmo assim encontrou o que procurava em aplicativos como Spotify, Netflix ou Amazon.\nNÃ£o, nÃ£o tem ninguÃ©m lendo seus pensamentos, na real tem um sistema muito interessante e bem desenvolvido por trÃ¡s, o Elasticsearch!\nEscrevi um documento explicando como ele funciona utilizando o Spotify como exemplo, e a designer\nMelissa Cavalcante\nfez um lindo design pra melhorar a absorÃ§Ã£o da informaÃ§Ã£o, recomendo dar uma olhada no perfil dela!\nCaso o assunto te interesse, recomendo pesquisar um pouco sobre Embedding SemÃ¢ntico, uma tÃ©cnica usada atÃ© no ChatGPT que distribui palavras em vetores para entender contextos e palavras escritas erradas, mas sÃ³ se vocÃª nÃ£o quiser ficar com um pouco de medo da inteligÃªncia artificial ğŸ¤­\nMuito obrigado pela leitura e bons estudos!",
    "image_path": "linkedin_images/post_image_3.jpg"
  },
  {
    "author": "LucÃ­ola Coelho",
    "description": "A\nhashtag\n#\nMicrosoft\nacaba de lanÃ§ar uma sÃ©rie GRATUITA de 18 episÃ³dios sobre IA generativa.\nIdeal para pessoas que sÃ£o novas na IA e querem comeÃ§ar a aprender.\nAqui estÃ£o 5 episÃ³dios que se destacaram\nVocÃª levarÃ¡ menos de 1,5 horas para assistir a todos estes:\nğŸ‘‰ IntroduÃ§Ã£o Ã  IA generativa e LLMs\nhttps://lnkd.in/dxds5CXY\nğŸ‘‰ Explorando e comparando diferentes LLMs\nhttps://lnkd.in/dnu5sP68\nğŸ‘‰ Entendendo os fundamentos da engenharia de prompt\nhttps://lnkd.in/d8t56acG\nğŸ‘‰ Criando aplicativos de IA low-code\nhttps://lnkd.in/dKVXmdeK\nğŸ‘‰ Agentes de IA â€“ Apresenta Agentes de IA, onde os LLMs podem realizar aÃ§Ãµes por meio de ferramentas ou estruturas.\nhttps://lnkd.in/d8VKw7Ve\nReposte esta postagem para ajudar outras pessoas em sua rede.\nâ—¾ Ã‰ Hoje!!!Â Abrimos as inscriÃ§Ãµes Ã s 10h.\nDia 1Âº de Julho a\nhashtag\n#\nEscolaIA\nvai abrir as inscriÃ§Ãµes em um formato novo!\nSiga\nLucÃ­ola Coelho\npara Aprender com uma\nhashtag\n#\nEngenheiraIA\n.\nhashtag\n#\nEscolaIA\nhashtag\n#\nA1ÂªEscolaIAdoBrasil\nhashtag\n#\nAgÃªnciaAIIA\nhashtag\n#\nA1ÂªAgÃªnciaIAdoBrasil\nhashtag\n#\nCursoIA\nhashtag\n#\nHotmart\nhashtag\n#\nCertificaÃ§Ã£oIA",
    "image_path": "linkedin_images/post_image_4.jpg"
  },
  {
    "author": "Ronnan Lima",
    "description": "ğŸš¨ NOTÃCIA URGENTE PARA DADOS E IAğŸš¨\nDatabricks\nlanÃ§ou algo que PARECE MENTIRA â€” mas Ã© 100% real:\nDatabricks\nFree Edition acabou de chegar.\nE ela vai explodir as portas da inteligÃªncia de dados para o mundo todo.\n(gratuito. ilimitado. sem pegadinhas.)\nVeja o que vocÃª pode fazer agora â€” sem pagar um centavo:\n1 - Construir dashboards, agentes de IA e modelos preditivos\n2 - Aprender habilidades prÃ¡ticas em engenharia de dados e IA\n3 - Usar a mesma plataforma que empresas gigantes utilizam\n4 - Colaborar com uma comunidade global de profissionais\nE o melhor: Totalmente gratuito. Para sempre.\n(Apenas uso pessoal, sem fins comerciais)\nSe vocÃª Ã© estudante, curioso ou futuro pro da Ã¡rea de dados...\nEssa Ã© sua chance de aprender como os profissionais...com as ferramentas dos profissionais.\nVeja o anÃºncio oficial do CEO da Databricks,\nAli Ghodsi\n:\nğŸ‘‰\nhttps://lnkd.in/dEiP9dhF\nEstaaaaaa esperando o queeeee?\nE vocÃª pode comeÃ§ar agora:\nhttps://lnkd.in/dADxaSZ7",
    "image_path": "linkedin_images/post_image_5.jpg"
  },
  {
    "author": "SÃ©rgio Henrique",
    "description": "ğŸš¨ VocÃª criou um dashboard incrÃ­vel, masâ€¦ e a documentaÃ§Ã£o?\nQuem nunca abriu um dashboard e ficou se perguntando:\nQual era o objetivo disso aqui mesmo?\nQue dado Ã© esse?\nComo navega?\nQuem fez?\nA verdade Ã© que dashboards incrÃ­veis tambÃ©m precisam ser documentados. Sem isso, viram labirintos de grÃ¡ficos bonitosâ€¦ e confusos.\nPensando nisso, aqui vai um guia prÃ¡tico (e visual!) com os principais elementos que vocÃª precisa documentar:\nObjetivo do Dashboard\nExplique claramente por que ele existe. O que ele responde? Qual decisÃ£o ele orienta?\nPÃºblico-alvo\nPara quem foi feito? Ajuda a garantir que a comunicaÃ§Ã£o esteja adequada.\nFontes de dados\nListe as origens dos dados utilizados. TransparÃªncia gera confianÃ§a.\nDefiniÃ§Ãµes dos indicadores\nDescreva cada mÃ©trica apresentada. Nada de â€œtaxa Xâ€ sem contexto!\nEstrutura do dashboard\nComo as informaÃ§Ãµes estÃ£o organizadas? Isso facilita o entendimento geral.\nInstruÃ§Ãµes de acesso\nGuia simples para quem estÃ¡ entrando pela primeira vez.\nFiltros e interaÃ§Ãµes\nExplique como o usuÃ¡rio pode navegar. Tem drill-down? Tem filtros? Mostre como usar!\nResponsÃ¡veis\nQuem criou, mantÃ©m, ou pode responder dÃºvidas sobre o dashboard?\nHistÃ³rico de atualizaÃ§Ãµes\nManter um log das mudanÃ§as ajuda a entender variaÃ§Ãµes de dados com o tempo.\nLimitaÃ§Ãµes conhecidas\nNenhum dashboard Ã© perfeito. Ser honesto sobre as limitaÃ§Ãµes Ã© sinal de maturidade analÃ­tica.\nğŸ’¡ Dica final: Documentar bem um dashboard Ã© um ato de empatia com o prÃ³ximo analistaâ€¦ e com vocÃª mesmo no futuro!\nhashtag\n#\nDataViz\nhashtag\n#\nBI\nhashtag\n#\nDashboard\nhashtag\n#\nAnÃ¡liseDeDados\nhashtag\n#\nDataLiteracy\nhashtag\n#\nComunicaÃ§Ã£oDeDados\nhashtag\n#\nLinkedIn",
    "image_path": "linkedin_images/post_image_6.jpg"
  },
  {
    "author": "Erickson Lopes",
    "description": "ğŸš€ Dica de Python: Criando agentes inteligentes com CrewAI! ğŸ¤–ğŸ\nVocÃª jÃ¡ ouviu falar do CrewAI? Ã‰ uma biblioteca poderosa para criar agentes de IA colaborativos, ideal para tarefas autÃ´nomas, anÃ¡lises, resumos, e atÃ© automaÃ§Ã£o de decisÃµes.\nNesta dica, montei um exemplo simples que responde Ã  clÃ¡ssica pergunta:\n\"Por que o cÃ©u Ã© azul?\" â˜ï¸ğŸ”µ\nCom poucos blocos de cÃ³digo, criamos:\nğŸ§  Um agente com papel, objetivo e histÃ³rico definidos\nâœ… Uma tarefa clara com descriÃ§Ã£o e saÃ­da esperada\nğŸ¤ Uma equipe para executar tudo de forma orquestrada\nEssa estrutura Ã© perfeita para explorar a criaÃ§Ã£o de assistentes, copilotos e automaÃ§Ãµes inteligentes com modelos da OpenAI via LangChain.\nâ¡ï¸ RepositÃ³rio:\nhttps://lnkd.in/dYE2WPDJ\nâ†©ï¸ Dica anterior:\nhttps://lnkd.in/dU6HbTDD\nğŸ”— Se curtiu, salva aÃ­ pra testar depois!\nhashtag\n#\nPython\nhashtag\n#\nInteligÃªnciaArtificial\nhashtag\n#\nCrewAI\nhashtag\n#\nLangChain\nhashtag\n#\nDesenvolvimentoDeSoftware\nhashtag\n#\nAutomaÃ§Ã£o\nhashtag\n#\nDicasDePython\nhashtag\n#\nIA",
    "image_path": "linkedin_images/post_image_7.jpg"
  },
  {
    "author": "Leo Candido",
    "description": "A Apple resolveu jogar um balde de Ã¡gua fria na capacidade de raciocÃ­nio dos LLMs. O Famoso \"pensando...\".\nQue eles realmente nÃ£o pensam a gente jÃ¡ sabia. Mas esse estudo traz coisas bem interessantes que valem a leitura do artigo e com certeza a discussÃ£o tambÃ©m.\nEnquanto OpenAI, Anthropic e Google promovem seus â€œmodelos que pensamâ€ como avanÃ§os rumo Ã  AGI, o artigo da Apple traz uma outra perspectiva pra narrativa.\nO artigo â€œThe Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexityâ€ traz essa perspectiva.\nEles testaram modelos em puzzles clÃ¡ssicos com complexidade crescente (Tower of Hanoi, River Crossing, Blocks World etc).\nA ideia? Avaliar nÃ£o sÃ³ se o modelo acerta, mas como ele \"pensa\" durante o processo.\nResultado?\n- Em tarefas simples, os modelos sem raciocÃ­nio foram melhores.\n- Em tarefas mÃ©dias, os LRMs (Large Reasoning Models) com â€œchain-of-thoughtâ€ se destacaram.\n- Em tarefas complexas, todos colapsaram. Inclusive os mais sofisticados.\nQuanto mais difÃ­cil o problema, menos tokens os modelos usaram para pensar.\nOu seja, quando mais precisam raciocinar... eles desistem.\nA crÃ­tica da Apple basicamente Ã© reforÃ§ar que o que muitos interpretam como raciocÃ­nio, pode ser na prÃ¡tica, apenas um alinhamento estatÃ­stico cada vez mais convincente, um comportamento que simula lÃ³gica, mas sem compreender de fato o que estÃ¡ fazendo.\nIsso obviamente nÃ£o significa que os modelos sÃ£o inÃºteis. Nem que o estudo encerra a discussÃ£o.\nOpenAI, Anthropic e Google tÃªm feito avanÃ§os reais e prÃ¡ticos na integraÃ§Ã£o de IA em ambientes corporativos e aplicaÃ§Ãµes do mundo real.\nMas talvez a palavra â€œraciocÃ­nioâ€ esteja sendo usada com generosidade demais.\nO estudo Ã© uma contribuiÃ§Ã£o interessante nÃ£o por desacreditar os modelos, mas por desafiar a narrativa de que eles jÃ¡ entendem o que fazem.\nComenta aÃ­. Bora debater.\nLink do estudo nos comentÃ¡rios!",
    "image_path": "linkedin_images/post_image_8.jpg"
  },
  {
    "author": "Bruno Aranda",
    "description": "VocÃª comeÃ§a a montar seu modelo de dadosâ€¦\nE trava.\n(acontece com todo mundo)\nA dÃºvida Ã© sempre a mesma:\nğŸ‘‰ Isso aqui Ã© fato ou Ã© dimensÃ£o?\nSe vocÃª jÃ¡ passou por isso, esse carrossel Ã© pra vocÃª.\nSem teoria demais.\nSem blÃ¡-blÃ¡-blÃ¡.\nSÃ³ o essencial â†’ com exemplos visuais.\nMostro na prÃ¡tica como as tabelas se conectam â€” e por quÃª.\nSe vocÃª quer dominar modelagem de dados,\nesse conteÃºdo vai te poupar horas de tentativa e erro.\nğŸ“Œ Salva pra rever depois\nğŸ‘‡ E comenta: qual parte da modelagem mais te confunde?\nhashtag\n#\nPowerBI\nhashtag\n#\nSQL\nhashtag\n#\nModelagemDeDados\nhashtag\n#\nAnalytics\nhashtag\n#\nBusinessIntelligence",
    "image_path": "linkedin_images/post_image_9.jpg"
  },
  {
    "author": "Sabrina Otoni",
    "description": "Hoje a nossa comunidade teve a honra de receber dois excelentes profissionais da Ã¡rea de Data Analytics:\nCaio Costa\n(analista de dados do\nItaÃº Unibanco\n) e\nCaio GuimarÃ£es\n(analista de dados da\nRappi\n). Deram um show trazendo uma visÃ£o muito rica para nÃ³s sobre os desafios e o dia a dia da Ã¡rea nesses diferentes setores.\nForam muitos insights, mas quero destacar especialmente uma reflexÃ£o sobre a importÃ¢ncia da comunicaÃ§Ã£o clara e assertiva na hora de apresentar resultados e anÃ¡lises para diferentes stakeholders. Saber contextualizar suas escolhas, traduzindo dados em decisÃµes estratÃ©gicas compreensÃ­veis para qualquer nÃ­vel organizacional, Ã© um dos principais diferenciais na nossa carreira em dados.\nA troca ao final da palestra foi incrÃ­vel... a proximidade, a troca genuÃ­na e os relatos pessoais mostraram que, de fato, nÃ£o existe crescimento sozinho. Receber feedbacks tÃ£o positivos sÃ³ reforÃ§a o quanto estamos no caminho certo, construindo uma comunidade colaborativa onde todos evoluem juntos.\nSe vocÃª tambÃ©m quer crescer conosco e participar de momentos como esse, fica aqui meu convite especial: venha fazer parte da roubAI Community, Ã© sÃ³ me mandar uma mensagem! nÃ³s ficaremos muito felizes em te ter conosco. ğŸ˜Š",
    "image_path": "linkedin_images/post_image_10.jpg"
  },
  {
    "author": "Yan Arcanjo",
    "description": "Arquitetura Medallion na prÃ¡tica: pipelines de dados com clareza, escalabilidade e propÃ³sito\nNa engenharia de dados, aplicar uma arquitetura em camadas como a Medallion â€” Staging (Landing Zone) > Bronze > Silver > Gold > Platinum â€” Ã© essencial para transformar dados brutos em ativos confiÃ¡veis, rastreÃ¡veis e prontos para gerar valor ao negÃ³cio.\nAqui estÃ¡ como aplico esse modelo no processamento de tabelas fato:\n1. Staging (Landing Zone) â€“ ingestÃ£o bruta, sem transformaÃ§Ãµes\nCom Apache Airflow, orquestro a ingestÃ£o diÃ¡ria dos Ãºltimos X dias da origem (banco, API, arquivos). Essa abordagem incremental permite capturar alteraÃ§Ãµes retroativas sem reprocessar tudo. Os dados chegam em formato bruto (geralmente Parquet), preservando sua integridade original.\n2. Bronze â€“ estrutura padronizada e confiÃ¡vel\nUtilizando PySpark, processamos os dados da Staging com upsert por partiÃ§Ãµes de data, removendo duplicidades e garantindo consistÃªncia. Essa camada mantÃ©m os dados historizados e tecnicamente organizados.\n3. Silver â€“ dados tratados e integrados\nAqui realizamos transformaÃ§Ãµes intermediÃ¡rias: joins, enriquecimentos, padronizaÃ§Ãµes, filtros e ajustes de schema. Os dados ganham uma estrutura analÃ­tica bÃ¡sica, prontos para exploraÃ§Ã£o e validaÃ§Ãµes.\nPara esse tratamento, alÃ©m do PySpark, tambÃ©m Ã© possÃ­vel utilizar o dbt, que facilita a criaÃ§Ã£o de transformaÃ§Ãµes SQL versionadas, reutilizÃ¡veis e documentadas.\n4. Gold â€“ a camada do negÃ³cio\nNa Gold Ã© onde todas as regras de negÃ³cio sÃ£o aplicadas.\nAs tabelas sÃ£o construÃ­das para atender diretamente Ã s necessidades das Ã¡reas, com cÃ¡lculos, hierarquias, mÃ©tricas, dimensÃµes e agregaÃ§Ãµes definidas.\nO dbt tambÃ©m pode ser utilizado aqui para garantir organizaÃ§Ã£o, governanÃ§a e testes automatizados nos modelos de negÃ³cio.\n5. Platinum â€“ produtos de dados especializados\nVisÃµes refinadas para data science, modelos preditivos, anÃ¡lises avanÃ§adas ou relatÃ³rios estratÃ©gicos sob demanda. Ã‰ a camada que entrega inteligÃªncia de forma estruturada.\nOs dados podem ser armazenados tanto em ambientes em nuvem como o BigQuery quanto em data warehouses locais, como SQL Server ou PostgreSQL, dependendo da arquitetura e infraestrutura da empresa.\nA visualizaÃ§Ã£o final Ã© feita no Power BI, conectando-se diretamente Ã s camadas Gold e Platinum, garantindo dashboards performÃ¡ticos, confiÃ¡veis e atualizados com base em pipelines auditÃ¡veis.\nEssa arquitetura â€” orquestrada com Airflow, transformada com PySpark e dbt, armazenada em ambientes locais ou cloud, e visualizada via Power BI â€” entrega soluÃ§Ãµes escalÃ¡veis e sustentÃ¡veis para dados em produÃ§Ã£o.\nhashtag\n#\nEngenhariaDeDados\nhashtag\n#\nArquiteturaMedallion\nhashtag\n#\nStaging\nhashtag\n#\nLandingZone\nhashtag\n#\nAirflow\nhashtag\n#\nPySpark\nhashtag\n#\ndbt\nhashtag\n#\nBigQuery\nhashtag\n#\nSQLServer\nhashtag\n#\nPostgreSQL\nhashtag\n#\nPowerBI\nhashtag\n#\nDataPipeline\nhashtag\n#\nDataOps\nhashtag\n#\nVagasTI",
    "image_path": "linkedin_images/post_image_11.jpg"
  },
  {
    "author": "Vitoria Freire",
    "description": "Como usei Machine Learning para apoiar decisÃµes de crÃ©dito com mais precisÃ£o e seguranÃ§a\nEmpresas que operam com concessÃ£o de crÃ©dito enfrentam um desafio claro: antecipar o risco de inadimplÃªncia antes da aprovaÃ§Ã£o.\nNeste projeto, desenvolvi uma soluÃ§Ã£o preditiva baseada em dados reais, com resultados consistentes e replicÃ¡veis.\nObjetivo do projeto\nConstruir um modelo de Machine Learning capaz de classificar clientes com maior ou menor risco de inadimplÃªncia com base em atributos como renda, comportamento de pagamento e perfil financeiro.\nO que foi feito:\n- AnÃ¡lise exploratÃ³ria com destaque para renda, dÃ­vidas e atrasos.\n- TransformaÃ§Ã£o de variÃ¡veis e normalizaÃ§Ã£o de renda (log1p).\n- Treinamento e otimizaÃ§Ã£o com validaÃ§Ã£o cruzada estratificada (GridSearchCV).\nComparaÃ§Ã£o de modelos:\n- RegressÃ£o LogÃ­stica\n- Random Forest\n- XGBoost\n- LightGBM\nResultados (AUC):\n- XGBoost: 0.86\n- LightGBM: 0.86\n- Random Forest: 0.86\n- Logistic Regression: 0.79\nTodos os modelos de Ã¡rvore obtiveram excelente desempenho, com precisÃ£o, recall e F1-score equilibrados.\nO Random Forest, por exemplo, alcanÃ§ou F1 de 0.78 com apenas 10 nÃ­veis de profundidade.\nPrincipais insights:\n- debt_ratio > 0.6 â†’ forte indicador de inadimplÃªncia (>50%).\n- Atrasos anteriores sÃ£o os melhores preditores de risco.\n- Faixas etÃ¡rias de 30â€“50 anos concentram maior volume de inadimplÃªncia.\n- AplicaÃ§Ã£o de regras de crÃ©dito por faixa de risco aumenta seguranÃ§a na concessÃ£o.\nTecnologias utilizadas:\n- Python, Pandas, NumPy, Scikit-Learn, XGBoost, LightGBM, Matplotlib, Seaborn\n- ValidaÃ§Ã£o com GridSearchCV + StratifiedKFold\nAplicaÃ§Ãµes diretas\n- ClassificaÃ§Ã£o de risco automatizada no momento da solicitaÃ§Ã£o\n- Apoio Ã  tomada de decisÃ£o em CRMs, sistemas de onboarding ou renegociaÃ§Ã£o\n- Base para construÃ§Ã£o de APIs de scoring e painÃ©is executivos com Streamlit\nğŸ“ Projeto completo no Kaggle:\nhttps://lnkd.in/d5SHVctE\nhashtag\n#\nDataScience\nhashtag\n#\nMachineLearning\nhashtag\n#\nCreditScoring\nhashtag\n#\nXGBoost\nhashtag\n#\nLightGBM\nhashtag\n#\nFintech\nhashtag\n#\nPython\nhashtag\n#\nModelagemPreditiva\nhashtag\n#\nProjetosDeDados\nhashtag\n#\nCiÃªnciaDeDados",
    "image_path": "linkedin_images/post_image_12.jpg"
  },
  {
    "author": "Quant Insider",
    "description": "Why it's better to use Seasonal ARIMAX (SARIMAX)  than ARIMA for seasonal forecasting\nThe Seasonal ARIMAX (SARIMAX) model extends ARIMA by incorporating seasonal components to forecast time series that display both trend and seasonality.\nWhile ARIMA uses p (autoregressive order), d (differencing for stationarity), and q (moving average order) to capture trends, it cannot model seasonal cycles. SARIMAX adds seasonal parametersâ€”P (seasonal autoregressive order), D (seasonal differencing order), Q (seasonal moving average order), and m (the seasonal period, such as 12 for monthly data with yearly seasonality)â€”resulting in the model notation SARIMAX(p, d, q)(P, D, Q)m.\nThe model assumes that the series becomes stationary after differencing and that residuals are white noise, ensuring all significant patterns are captured.\nSARIMAX is generally better than ARIMA for seasonal forecasting because it\nIncorporation of Seasonal Components:\nSARIMAX directly integrates seasonal components into the model using seasonal parameters (P, D, Q, s).\nARIMA handles trends but does not include seasonal components, requiring manual differencing to address seasonality.\nHandling of External Variables:\nSARIMAX supports exogenous variables, allowing the model to include external factors such as economic indicators or weather conditions.\nThe inclusion of these variables can further improve forecast accuracy.\nModel Flexibility and Applicability:\nSARIMAX is more flexible and powerful for datasets with clear seasonal behavior (e.g., monthly or quarterly cycles).\nIt naturally models recurring seasonal patterns, making it more appropriate for seasonal forecasting.\nTypical Domains of Application:\nSARIMAX is widely used in sales forecasting, financial market analysis, and inventory management, where seasonal patterns are significant.\nHyperparameter Sensitivity and Tuning:\nModel performance in SARIMAX is highly sensitive to hyperparameter selection.\nTuning is often performed using tools like AIC/BIC and grid search to find the optimal model parameters.\nTo learn how to implement a Time series model in quantitative finance, enroll in the Quantitative Finance Accelerator ProgramÂ is built in Collaboration with LAQSA (\nLambda Quant\n).\nPankaj Mani(Jha)\nRishi Kohli\nQuantitative Finance Accelerator Program is a comprehensive, cohort-based course designed to take you from the fundamentals to advanced quantitative finance expertise. This program covers a broad range of topics, starting with the essential principles of statistics, mathematics, and coding and advancing through quantitative analysis, modeling, risk management, data science, AI/ML applications, portfolio management, and algorithmic trading strategies.\nEnrollment is open now:\nhttps://lnkd.in/gk-jp-vk\nCourse Brochure Link -\nhttps://lnkd.in/gyhRqfBH\nEarly bird discount of 20%. Use coupon code \"EARLYQFA20\"\nFor queries\nPhone number - 8349489231\nEmail -\neducation@quantinsider.io",
    "image_path": "linkedin_images/post_image_13.jpg"
  },
  {
    "author": "Quant Insider",
    "description": "List of types of Regression of Generalised Linear Models (GLMS), including explanations and use case examples.\nLogistic Regression\nUsed for binary classification tasks where the response variable takes values 0 or 1.\nIt models the log-odds of the probability using the logistic (sigmoid) function.\nCommonly applied in credit scoring, fraud detection, and churn prediction.\nMultinomial Logistic Regression\nGeneralization of logistic regression to handle multi-class problems with more than two possible outcomes.\nIt models the probabilities of each class using a softmax function.\nUseful in text classification, image recognition, and recommendation systems.\nPoisson Regression\nDesigned for modeling count data, where the dependent variable represents the number of occurrences of an event.\nAssumes the response variable follows a Poisson distribution with a log link function.\nUsed in insurance claim prediction, call center traffic, and public health incident rates.\nGamma Regression\nSuitable for modeling continuous, positive, right-skewed data where the variance increases with the mean.\nAssumes a Gamma distribution for the response and often uses an inverse or log link.\nCommon in modeling waiting times, survival data, and insurance payouts.\nProbit Regression\nSimilar to logistic regression, but models the inverse of the standard normal cumulative distribution function.\nPreferred when the latent variable is assumed to follow a normal distribution.\nApplied in econometrics, choice modelling, and psychological testing.\nIf you want to build a career in Quant Finance, enroll now in our Quantitative Finance Accelerator (QFA) built in Collaboration with LAQSA (\nLambda Quant\n)\nQuantitative Finance Accelerator Program is a comprehensive, cohort-based course designed to take you from the fundamentals to advanced quantitative finance expertise. This program covers a broad range of topics, starting with the essential principles of statistics, mathematics, and coding and advancing through quantitative analysis, modeling, risk management, data science, AI/ML applications, portfolio management, and algorithmic trading strategies.\nThe course is taught by industry practitioners with over 20+ years of experience, ensuring practical insights and real-world applications\nWhat Youâ€™ll Learn:\nâœ” Core concepts in statistics, probability, and time series\nâœ” Python for financial applications\nâœ” Quant models & derivatives pricing\nâœ” Machine learning & AI in finance\nâœ” Portfolio theory, risk management, and algo trading\nâœ” Final Capstone Project to apply what you've learned\nAccessible via our custom Web + Mobile App with lifetime access to:\nRecorded lectures\nAnnotated notes\nPython labs\nOffline learning\nCourse Link -\nhttps://lnkd.in/gTwQkrRt\nCourse Brochure Link -\nhttps://lnkd.in/gyhRqfBH\nWe are giving an early bird discount of 25%. Use coupon code \"QFA25\"\nFor queries\nPhone - 8349489231\nEmail -\neducation@quantinsider.io",
    "image_path": "linkedin_images/post_image_14.jpg"
  },
  {
    "author": "Felipe Coutinho",
    "description": "VocÃª nÃ£o precisa ser um gÃªnio da matemÃ¡tica para comeÃ§ar em Machine Learning. SÃ©rio mesmo.\nQuando comecei minha jornada em ML, achava que precisava dominar cÃ¡lculo, Ã¡lgebra linear e estatÃ­stica antes de escrever uma linha de cÃ³digo. Resultado? ProcrastinaÃ§Ã£o e ansiedade.\nA verdade Ã© que vocÃª pode comeÃ§ar HOJE mesmo com conhecimentos bÃ¡sicos.\nPara quem estÃ¡ construindo modelos e aplicaÃ§Ãµes (e nÃ£o criando novos algoritmos), bibliotecas como NumPy, scikit-learn e TensorFlow fazem o trabalho pesado matemÃ¡tico por vocÃª.\nÃ‰ como dirigir um carro, vocÃª nÃ£o precisa entender o funcionamento do motor para chegar ao seu destino.\nMas atenÃ§Ã£o: em algum momento, a matemÃ¡tica se torna crucial. Quando seu modelo nÃ£o converge ou vocÃª precisa interpretar coeficientes corretamente, aquele conhecimento matemÃ¡tico faz toda diferenÃ§a.\nConstrua projetos e aprenda matemÃ¡tica PARALELAMENTE:\nâœ¦ Ãlgebra Linear: matrizes, vetores, operaÃ§Ãµes bÃ¡sicas\nâœ¦ CÃ¡lculo: derivadas, gradientes e a regra da cadeia\nâœ¦ EstatÃ­stica: distribuiÃ§Ãµes, variÃ¢ncia e teorema de Bayes\nRecursos que facilitam o aprendizado:\nâ†’ Three Blue One Brown (YouTube): visualizaÃ§Ãµes incrÃ­veis\nâ†’ StatQuest: explicaÃ§Ãµes claras e diretas\nâ†’ Cursos da Coursera: Mathematics for Machine Learning\nUma dica Ã© tentar traduzir  fÃ³rmulas para linguagem simples que fazem mais sentido para vocÃª. Y = aX + b vira \"resultado = inclinaÃ§Ã£o Ã— entrada + ponto inicial\".\nComece construindo. Treine modelos. Explore dados. A matemÃ¡tica virÃ¡ naturalmente quando vocÃª precisar resolver problemas reais.\nE se vocÃª quer acelerar sua jornada em dados com conteÃºdo prÃ¡tico e acessÃ­vel, a Universidade dos Dados oferece um programa completo por apenas 12x de R$31,64 no plano anual. Uma comunidade com mais de 1400 estudantes e 99% de avaliaÃ§Ãµes positivas te espera!\nCompartilhe se esse post te ajudou a diminuir seu medo da matemÃ¡tica em ML! ğŸš€",
    "image_path": "linkedin_images/post_image_15.jpg"
  },
  {
    "author": "VÃ¢nia Paula",
    "description": "Assista as aulas abaixo (organizadas na sequÃªncia que vocÃª deve estudar, do bÃ¡sico ao avanÃ§ado):\nA1 â€“ Iniciante:\nlnkd.in/exfQ_XDq\nA2 â€“ BÃ¡sico:\nlnkd.in/eb4fnF9f\nB1 â€“ IntermediÃ¡rio:\nlnkd.in/e8XVJg-Q\nB2 â€“ IntermediÃ¡rio Superior:\nlnkd.in/edTjGqHA\nC1 â€“ AvanÃ§ado:\nlnkd.in/eQf88gJr\nC2 â€“ Proficiente:\nlnkd.in/e9EFRaNu\nâ†³ Planejamento de 3 meses:\nlnkd.in/eVdaTYhk\nâ†³ Planejamento de 6 meses:\nlnkd.in/eNivwP26\nâ†³ Planejamento de 12 meses:\nlnkd.in/ezQC7QZ3\nğŸ“– Quer apostilas gratuitas? Temos tambÃ©m:\nlnkd.in/eZ4cVSua\nCompartilhe e ajude sua rede ğŸ’™ğŸ‘¥",
    "image_path": "linkedin_images/post_image_16.jpg"
  },
  {
    "author": "Reed Iury",
    "description": "ğŸš€ Card com Efeito Glass no Power BI\nFala, pessoal! ğŸ‘‹\nSe vocÃª curte visuais diferentes no Power BI, preparei um template especial com efeito glassmorphism â€“ aquele efeito com transparÃªncia e desfoque. TÃ¡ prontinho pra usar!\nâœ¨ O que tem no template?\nâœ… Efeito vidro (blur + transparÃªncia).\nâœ… Design responsivo que se adapta a qualquer layout.\nâœ… Ãcones e animaÃ§Ãµes pra deixar tudo mais fluido.\nâœ… Cores personalizÃ¡veis (Ã³timo pra destacar mÃ©tricas boas/ruins).\nğŸ’¡ Como usar?\n1ï¸âƒ£ Baixe o .PBIX (link nos comentÃ¡rios)\n2ï¸âƒ£ Ajuste os valores direto nas medidas DAX\n3ï¸âƒ£ Personalize as cores e deixe com a cara do seu projeto\nAh, e se conhece alguÃ©m que curte dashboards criativos, marca aqui! ğŸ”\nhashtag\n#\nPowerBI\nhashtag\n#\nDashboard\nhashtag\n#\nDataViz\nhashtag\n#\nBusinessIntelligence\nhashtag\n#\nTecnologia\nhashtag\n#\nDesign\nhashtag\n#\nHTML",
    "image_path": "linkedin_images/post_image_17.jpg"
  },
  {
    "author": "Renata Costa",
    "description": "Acabou as desculpas de â€œnÃ£o sei por onde comeÃ§ar a estudar estatÃ­sticaâ€",
    "image_path": "linkedin_images/post_image_18.jpg"
  },
  {
    "author": "Avi Chawla",
    "description": "11 plots in data science that are used 90% of the time\n(with precise usageğŸ‘‡)\nVisualizations are critical in understanding complex data patterns and relationships.\nThey offer a concise way to understand the:\n- intricacies of statistical models\n- validate model assumptions\n- evaluate model performance, and much more.\nThe visual below depicts theÂ 11 mostÂ important and must-know plots in data science:\n1) KS Plot:\n- It is used to assess the distributional differences.\n- The core idea is to measure the maximum distance between the cumulative distribution functions (CDF) of two distributions.\n- The lower the maximum distance, the more likely they belong to the same distribution.\n- Thus, instead of a â€œplotâ€, it is mainly interpreted as a â€œstatistical testâ€ to determine distributional differences.\n2) SHAP Plot:\n- It summarizes feature importance to a modelâ€™s predictions by considering interactions/dependencies between them.\n- It is useful in determining how different values (low or high) of a feature affect the overall output.\n3) ROC Curve:\n- It depicts the tradeoff between the true positive rate (good performance) and the false positive rate (bad performance) across different classification thresholds.\n4) Precision-Recall Curve:\n- It depicts the tradeoff between Precision and Recall across different classification thresholds.\n5) QQ Plot:\n- It assesses the distributional similarity between observed data and theoretical distribution.\n- It plots the quantiles of the two distributions against each other.\n- Deviations from the straight line indicate a departure from the assumed distribution.\n6) Cumulative Explained Variance Plot:\n- It is useful in determining the number of dimensions we can reduce our data to while preserving max variance during PCA.\n7) Elbow Curve:\n- The plot helps identify the optimal number of clusters for the k-means algorithm.\n- The point of the elbow depicts the ideal number of clusters.\n8) Silhouette Curve:\n- The Elbow curve is often ineffective when you have plenty of clusters.\n- Silhouette Curve is a better alternative, as depicted above.\n9) Gini-Impurity and Entropy:\n- They are used to measure the impurity or disorder of a node or split in a decision tree.\n- The plot compares Gini impurity and Entropy across different splits.\n- This provides insights into the tradeoff between these measures.\n10) Bias-Variance Tradeoff:\n- It is used to find the right balance between the bias and the variance of a model against complexity.\n11) PDP:\n- Depicts the dependence between target and features.\n- A plot between the target and one feature forms â†’ 1-way PDP.\n- A plot between the target and two feature forms â†’ 2-way PDP.\nğŸ‘‰ Over to you: Do you find it easier to interpret plots over numbers?\n____\nIf you want to learn AI/ML engineering, get this free PDF (530+ pages) with 150+ core DS/ML lessons.\nGet here:\nhttps://lnkd.in/gi6xKmDc\n____\nFind me â†’\nAvi Chawla\nEvery day, I share tutorials and insights on DS, ML, LLMs, and RAGs.",
    "image_path": "linkedin_images/post_image_19.jpg"
  },
  {
    "author": "John Paz",
    "description": "ğŸš€ Como os Modelos de IA (LLMs) REALMENTE funcionam? ğŸ¤¯â¬‡ï¸\nOs grandes modelos de linguagem (LLMs) como ChatGPT nÃ£o \"pensam\", mas fazem algo incrivelmente poderoso. Vamos simplificar:\nğŸ”¹ TokenizaÃ§Ã£o & Embeddings\nğŸ“Œ O texto Ã© quebrado em tokens (pequenos pedaÃ§os).\nğŸ“Œ Cada token vira um vetor em um espaÃ§o multidimensional, onde palavras similares ficam prÃ³ximas.\nğŸ”¹ Mecanismo de AtenÃ§Ã£o (Self-Attention)\nğŸ” O modelo pesa o contexto, diferenciando \"banco\" (financeiro) de \"banco\" (de praÃ§a).\nğŸ” Cada palavra influencia as outras dinamicamente.\nğŸ”¹ Rede Neural Profunda & Processamento\nğŸ§  ApÃ³s a atenÃ§Ã£o, os tokens passam por vÃ¡rias camadas que refinam o significado.\nğŸ§  Quanto mais camadas, melhor o entendimento do contexto.\nğŸ”¹ PrevisÃ£o & GeraÃ§Ã£o de Texto\nğŸ”¢ O modelo gera a prÃ³xima palavra baseado em probabilidades, escolhendo a mais adequada a cada momento.\nğŸ’¡ Por que isso importa?\nğŸ”¹ Compreender esses mecanismos Ã© essencial para criar soluÃ§Ãµes de IA escalÃ¡veis e confiÃ¡veis.\nğŸ”¹ Toda decisÃ£o de um LLM vem dessas camadas e da forma como elas processam padrÃµes.\nğŸ¥ Quer entender melhor? Recomendo assistir e salvar esse vÃ­deo:\nğŸ‘‰\nhttps://lnkd.in/dAviqK_6\nO que vocÃª acha mais fascinante nos LLMs? Vamos discutir nos comentÃ¡rios! ğŸ’¬ğŸ‘‡\nO futuro jÃ¡ chegou. Para se manter Ã  frente do jogo, siga\nJohn Paz\n.\nhashtag\n#\nIA\nhashtag\n#\nMachineLearning\nhashtag\n#\nLLMs\nhashtag\n#\nDeepLearning\n#InovaÃ§Ã£o#\nNuvia\nCreditos: Andreas Horn",
    "image_path": "linkedin_images/post_image_20.jpg"
  },
  {
    "author": "Renata Costa",
    "description": "Da sÃ©rie: coisas que aprendi e que me ajudam muito como Analista de BI\nProva de Conceito (POC)\nA primeira vez que ouvi esse termo foi na documentaÃ§Ã£o da Microsoft, e achei incrÃ­vel sua praticidade e aplicabilidade â€” nÃ£o sÃ³ em projetos de BI, mas em diversas outras Ã¡reas.\nUma POC (Proof of Concept) Ã© uma implementaÃ§Ã£o inicial de um design, com escopo e maturidade limitados. Quando bem executada, permite identificar e lidar com complexidades (ou exceÃ§Ãµes) que poderiam passar despercebidas no inÃ­cio do projeto.\nNo inÃ­cio do projeto, recomenda-se reunir os stakeholders para discutir os seguintes pontos:\n1ï¸âƒ£ Objetivos e escopo do projeto\n2ï¸âƒ£ Origem dos dados\n3ï¸âƒ£ DemonstraÃ§Ã£o inicial (mockup ou draft)\n4ï¸âƒ£ Ferramentas de desenvolvimento\n5ï¸âƒ£ CritÃ©rios de sucesso\n6ï¸âƒ£ CritÃ©rios de falha\nDiscutam, registrem e validem! A prova de conceito Ã© um documento vivo, que deve ser revisitado constantemente para garantir que os conceitos definidos no inÃ­cio ainda fazem sentido.\nEla Ã© essencial para evitar retrabalho e alinhar as expectativas de todas as partes envolvidas.\nAgora, reparem no mockup: ele foi construÃ­do com base na POC. Ou seja, deve seguir os objetivos e escopo definidos, bem como atender aos critÃ©rios de sucesso estabelecidos.\nIMPORTANTE!\nğŸ“Œ VocÃª nÃ£o precisa esperar ser um(a) analista de dados para comeÃ§ar a usar a POC! Eu trouxe aqui um exemplo que estou incluindo no meu portfÃ³lio: me coloquei no lugar do stakeholder, estudei o processo e elaborei minha POC. Esse tipo de iniciativa agrega muito valor ao seu portfÃ³lio e demonstra que, alÃ©m do domÃ­nio das ferramentas, vocÃª tem uma visÃ£o estratÃ©gica dos processos!\nQuero saber de vocÃªs! ğŸ‘‡\nJÃ¡ conheciam a prova de conceito? JÃ¡ usaram sem saber? Ou agora vÃ£o aproveitar para colocar em prÃ¡tica? (Porque, mais uma vez: estudo sem prÃ¡tica Ã© entretenimento).\nE se vocÃª quer aprender mais sobre a Ã¡rea de Dados e BI, me siga aqui! Toda semana compartilho algo novo com a rede. ğŸ˜‰\nhashtag\n#\nprovadeconceito\nhashtag\n#\nanalisededados\nhashtag\n#\nbusinessintelligence\nhashtag\n#\npowerbi\n.",
    "image_path": "linkedin_images/post_image_21.jpg"
  },
  {
    "author": "Akshay Pachaar",
    "description": "Effortless Document Parsing with Docling!\nDocling is an open-source Python package that transforms any document into LLM ready data!\nKey Features:\nğŸ” OCR for scanned PDFs\nğŸ—‚ï¸ PDF, PPTX, DOCX & more â†’ Markdown, JSON\nğŸ“‘ Advanced PDF parsing: layout, reading order, tables\nğŸ¤– Integrates with LlamaIndex & LangChain\nComing Soon:\nâ™¾ï¸ Equation & code extraction\nğŸ¦œğŸ”— Native LangChain extension\nğŸ“ Metadata extraction (titles, authors, references & language)\nCompatible with macOS, Linux, and Windows on both x86_64 and arm64 architectures.\nGitHub repo:\nhttps://lnkd.in/gWgDw6Cr\nâ†“\nInterested in ML/AI Engineering? Sign up for our newsletter for in-depth lessons and get a FREE eBook with 150+ core DS/ML lessons:\nhttps://lnkd.in/gB7yHExC",
    "image_path": "linkedin_images/post_image_22.jpg"
  },
  {
    "author": "Karine Lago",
    "description": "Como usar a funÃ§Ã£o ALL da forma mais eficiente, aplicaÃ§Ã£o da DIVIDE, usando a SELECTEDVALUE, evitando o uso da IFERROR e ISERROR, habituando-se com a ISBLACK e melhores prÃ¡ticas de usos de filtros.\nVocÃª vai aprender tudo isso nesse post que merece ser salvo pra consultar depois!\nğŸ’¬ Me conta aqui nos comentÃ¡rios: Quantas tÃ©cnicas que mencionei acima vocÃª aprendeu agora?\nhashtag\n#\nDAX\nhashtag\n#\nPowerBI\nhashtag\n#\nMicrosoftPowerBI\nhashtag\n#\nDashboards\nhashtag\n#\nAnalytics\nhashtag\n#\nBusinessIntelligence",
    "image_path": "linkedin_images/post_image_23.jpg"
  },
  {
    "author": "Ajay Shenoy",
    "description": "Interested in GenAI/LLMs?\nğŸ”¥ğŸ”¥ 444 datasetsğŸ”¥ğŸ”¥\n774.5 TB â•‘ 8 Languages â•‘ 32 domains â•‘\nPre-training â‹ Fine tuning â‹ Evaluation\nYang Liu and co-authors, a big thank you ğŸ™\n(Links in the comment section)",
    "image_path": "linkedin_images/post_image_24.jpg"
  },
  {
    "author": "Leonardo Miralles",
    "description": "ğŸ› ï¸ A importÃ¢ncia dos fluxogramas\nUm fluxograma Ã© uma ferramenta essencial na visualizaÃ§Ã£o de processos, ajudando a organizar e entender o fluxo de atividades ou dados em um sistema ou projeto. Apesar de sua grande utilidade, os fluxogramas sÃ£o muitas vezes subestimados, especialmente quando se trata de empresas que negligenciam a importÃ¢ncia da documentaÃ§Ã£o adequada. Documentar processos de forma clara, usando fluxogramas, nÃ£o sÃ³ melhora a eficiÃªncia, como tambÃ©m facilita a comunicaÃ§Ã£o entre equipes.\nğŸ“Š Aqui estÃ£o os principais sÃ­mbolos e seus significados:\n-Elipse (ou Oval): Representa o inÃ­cio e o fim de um processo.\n-Seta: Indica o fluxo ou direÃ§Ã£o de um processo.\n-RetÃ¢ngulo: Usado para processos ou instruÃ§Ãµes que envolvem cÃ¡lculos e atribuiÃ§Ã£o de valores.\n-Paralelogramo: Simboliza a entrada e saÃ­da de dados no processo.\n-Losango: Indica a tomada de decisÃµes e escolhas, onde o fluxo pode seguir por diferentes caminhos.\nğŸ“ˆ O uso de fluxogramas deve ser valorizado nas empresas, pois simplifica processos complexos e melhora a clareza de comunicaÃ§Ã£o!\nhashtag\n#\nfluxograma\nhashtag\n#\ndocumentaÃ§Ã£o\nhashtag\n#\nprocessos\nhashtag\n#\neficiÃªncia\nhashtag\n#\ngestÃ£odeprojetos\nhashtag\n#\nmelhoresprÃ¡ticas\nhashtag\n#\norganizaÃ§Ã£o\nhashtag\n#\nprodutividade",
    "image_path": "linkedin_images/post_image_25.jpg"
  },
  {
    "author": "Akshay Pachaar",
    "description": "Ever seen one of those moving bubbles chartsâ“\nHereâ€™s how you can create one in Python with just 3 lines of code using D3Blocks!\nWhat you'll need:\n- A Pandas DataFrame where each row represents a sample state at a specific timestamp.\n- Utilize this DataFrame in the `movingbubbles()` method.\nThis will generate a moving bubbles chart like the one shown in the video below.\n----\nIf you enjoyed this, you should also check this FREE Data Science e-book featuring 150 essential lessons in DS and ML:\nblog.dailydoseofds.com\n----\nFind me â†’\nhttps://lnkd.in/em_V4unu\nâœ”ï¸\nFor more insights & tutorials on AI and Machine Learning.",
    "image_path": "linkedin_images/post_image_26.jpg"
  },
  {
    "author": "Leonardo Miralles",
    "description": "ğŸ“Œ MÃ©todos Importantes da biblioteca Pandas no Python\nAqui estÃ¡ uma breve descriÃ§Ã£o de cada comando em trÃªs categorias: Data Importing, Data Cleaning e Data Statistic. Esses mÃ©todos sÃ£o essenciais para quem trabalha com anÃ¡lise de dados usando Python.\nğŸ”¹ Data Importing\npd.read_csv() â€“ LÃª arquivos em formato CSV.\npd.read_table() â€“ LÃª arquivos delimitados por tabulaÃ§Ãµes ou outros delimitadores.\npd.read_excel() â€“ LÃª planilhas Excel em diferentes formatos (.xls, .xlsx).\npd.read_sql() â€“ Executa consultas SQL e importa os dados para um DataFrame.\npd.read_json() â€“ LÃª arquivos em formato JSON e converte em DataFrame.\npd.read_html() â€“ Extrai tabelas de arquivos HTML.\npd.DataFrame() â€“ Cria um DataFrame a partir de listas, dicionÃ¡rios ou arrays.\npd.concat() â€“ Junta DataFrames em um sÃ³, concatenando-os.\npd.series() â€“ Cria uma Series (estrutura unidimensional) no Pandas.\npd.date_range() â€“ Gera uma sequÃªncia de datas em um intervalo especÃ­fico.\nğŸ”¹ Data Cleaning\npd.fillna() â€“ Preenche valores ausentes (NaN) com um valor especificado.\npd.dropna() â€“ Remove linhas ou colunas com valores ausentes.\npd.sort_values() â€“ Ordena o DataFrame com base nos valores de uma coluna.\npd.apply() â€“ Aplica uma funÃ§Ã£o a cada elemento do DataFrame.\npd.groupby() â€“ Agrupa os dados em grupos com base em uma ou mais colunas.\npd.append() â€“ Anexa linhas de outro DataFrame ao final do atual.\npd.join() â€“ Junta DataFrames com base em uma chave comum.\npd.rename() â€“ Altera os rÃ³tulos das colunas ou linhas no DataFrame.\npd.to_csv() â€“ Exporta o DataFrame para um arquivo CSV.\npd.set_index() â€“ Define uma coluna como Ã­ndice do DataFrame.\nğŸ”¹ Data Statistic\npd.head() â€“ Retorna as primeiras n linhas do DataFrame.\npd.tail() â€“ Retorna as Ãºltimas n linhas do DataFrame.\npd.describe() â€“ Gera estatÃ­sticas descritivas resumidas para o DataFrame.\npd.info\n() â€“ Exibe informaÃ§Ãµes sobre o DataFrame, como nÃºmero de entradas e tipos de dados.\npd.mean() â€“ Calcula a mÃ©dia para cada coluna numÃ©rica.\npd.median() â€“ Calcula a mediana para cada coluna numÃ©rica.\npd.count() â€“ Conta o nÃºmero de entradas nÃ£o nulas para cada coluna.\npd.std() â€“ Calcula o desvio padrÃ£o para cada coluna numÃ©rica.\npd.max() â€“ Retorna o valor mÃ¡ximo para cada coluna numÃ©rica.\npd.min() â€“ Retorna o valor mÃ­nimo para cada coluna numÃ©rica.\nğŸ’¡ Dica: Conhecer e dominar esses mÃ©todos ajuda a tornar o trabalho com dados mais eficiente e Ã¡gil, garantindo uma anÃ¡lise de dados precisa.\n-------\nğŸŒŸ Me siga para vagas e dicas na Ã¡rea de dados\nhashtag\n#\nDataScience\nhashtag\n#\nPython\nhashtag\n#\nPandas\nhashtag\n#\nDataAnalysis\nhashtag\n#\nAnÃ¡liseDeDados\nhashtag\n#\nDataCleaning\nhashtag\n#\nDataImporting\nhashtag\n#\nDataStatistics\nhashtag\n#\nMachineLearning\nhashtag\n#\nPythonForDataScience\nhashtag\n#\nManipulaÃ§Ã£oDeDados\nhashtag\n#\nBigData\nhashtag\n#\nAprendizado",
    "image_path": "linkedin_images/post_image_27.jpg"
  },
  {
    "author": "Thaynara Sousa",
    "description": "As tabelas fato e dimensÃ£o sÃ£o essenciais para quem trabalha com anÃ¡lise de dados no Power BI!\nEnquanto a tabela fato concentra os dados numÃ©ricos e transacionais, como vendas e lucros, a tabela dimensÃ£o oferece o contexto necessÃ¡rio para anÃ¡lise, com informaÃ§Ãµes descritivas como produtos, clientes ou datas.\nA estruturaÃ§Ã£o correta desses componentes nÃ£o sÃ³ otimiza o desempenho das anÃ¡lises, como tambÃ©m facilita a criaÃ§Ã£o de relatÃ³rios eficientes, permitindo que os insights sejam gerados de forma rÃ¡pida e precisa.\nSe vocÃª quer elevar o nÃ­vel dos seus dashboards e anÃ¡lises, dominar o uso dessas tabelas Ã© fundamental!",
    "image_path": "linkedin_images/post_image_28.jpg"
  },
  {
    "author": "Pavan Belagatti",
    "description": "The 6 layers of\nhashtag\n#\nGenAI\ntech stack every AI/ML engineer should know.\nThe GenAI technology stack is a sophisticated, layered architecture designed to harness the power of large language models (LLMs) for real-world applications.\nAt its foundation lies the Infrastructure layer, comprising cloud platforms like AWS, Google Cloud, and Azure, or on-premise servers. This layer provides the essential computational resources and scalability needed to support AI operations.\nBuilt upon this is the Data layer, housing databases, data lakes, vector stores, and knowledge graphs. This layer is crucial for managing the vast amounts of data required for training and operating AI systems, ensuring efficient storage, retrieval, and updating of information.\nThe LLM layer sits at the core of the stack, featuring powerful models such as GPT-4, Claude, and BERT. These models serve as the engines of natural language understanding and generation, capable of processing and producing human-like text across various domains.\nThe API layer acts as a bridge, exposing the capabilities of these LLMs through standardized interfaces like the OpenAI API or Anthropic API. This abstraction allows developers to integrate AI capabilities into their applications without dealing with the complexities of model deployment and management.\nThe Application layer leverages frameworks like Langchain and Semantic Kernel to build sophisticated AI applications. These tools provide high-level abstractions for common AI tasks, enabling rapid development of complex, context-aware applications.\nFinally, the UI layer presents these AI capabilities to end-users through web interfaces, mobile apps, chatbots, and voice assistants, making the power of AI accessible and intuitive for non-technical users.\nThis layered approach ensures modularity, scalability, and flexibility, allowing organizations to adapt and evolve their AI systems as technology advances and business needs change.\nAdditional Considerations:\n- Ethical & Responsible AI: Ensure that your GenAI technology stack aligns with ethical guidelines & addresses potential biases.\n- Privacy & Security: Implement robust measures to protect user data & prevent unauthorized access.\n- Scalability & Performance: Design your stack to handle increasing workloads & ensure optimal performance.\n- Cost Optimization: Consider cost-effective options for hardware, software, & cloud services.\nNote: This is not a standard layered approach, you can pick tools, platforms, frameworks as per your use case.\n------------------------------------------------------------\nHaving a robust data platform like\nSingleStore\nto handle not just the vector but any type of data for your AI applications is highly recommended. SingleStore also supports features like hybrid search, real-time analytics, semantic cache, mili second latency, ultra fast ingestion, etc.\nTry SingleStore for FREE:\nhttps://lnkd.in/gCkYgV4H",
    "image_path": "linkedin_images/post_image_29.jpg"
  },
  {
    "author": "Heitor Sasaki",
    "description": "Excel: Ei, isso Ã© uma data nÃ©?\nVocÃª: 47.13 com certeza nÃ£o Ã© uma data\nExcel: Tem certeza? Parece muito uma data...\nVocÃª: NÃ£o Ã© uma data...\nExcel: Corrigido ğŸ§\nVocÃª: 47/13/1900 ???\nExcel: Sempre a seu dispor\nğŸ¤¡ Quem nunca?",
    "image_path": "linkedin_images/post_image_30.jpg"
  },
  {
    "author": "Fabio MarÃ§olia",
    "description": "EstÃ¡ aproveitando o potencial de IA para tarefas com Dados?\nNo dia a dia dentre muitos desafios, podemos usar IA como um assistente para:\n-Limpar e preparar datasets.\n-Analisar/otimizar erros em cÃ³digos.\n-Criar e otimizar pipelines de dados.\n-Documentar arquiteturas de dados.\n-Desenvolver consultas SQL precisas.\n-Gerar relatÃ³rios de BI automatizados.\n-Elaborar anÃ¡lises preditivas detalhadas.\nE muito mais.....\nMas para ser eficiente Ã© importante entender como estruturar seus pedidos, usando boas prÃ¡ticas de engenharia de prompts.\nEsse simples framework pode ajudar muito:\nğŸ­-ğ—”ğ˜ğ—¿ğ—¶ğ—¯ğ˜‚ğ—® ğ˜‚ğ—º ğ—½ğ—®ğ—½ğ—²ğ—¹\n-Defina o papel especÃ­fico para a tarefa (ex.: \"Atue como Engenheiro de Dados\").\nğŸ®-ğ—˜ğ˜€ğ˜ğ—®ğ—¯ğ—²ğ—¹ğ—²ğ—°Ì§ğ—® ğ—¼ ğ—¼ğ—¯ğ—·ğ—²ğ˜ğ—¶ğ˜ƒğ—¼\n-Explique claramente o que precisa ser entregue (ex.: \"Desenvolva um pipeline ETL\").\nğŸ¯-ğ—–ğ—¿ğ—¶ğ—² ğ—¿ğ—²ğ˜€ğ˜ğ—¿ğ—¶ğ—°Ì§ğ—¼Ìƒğ—²ğ˜€(ğ—–ğ—®ğ˜€ğ—¼ ğ—»ğ—²ğ—°ğ—²ğ˜€ğ˜€ğ—®Ìğ—¿ğ—¶ğ—¼)\n-Coloque o queÂ Â considerar ou nÃ£o (ex.: \"Use padrÃ£o SQL do SQL Server\").\nğŸ°-ğ——ğ—²ğ˜ğ—²ğ—¿ğ—ºğ—¶ğ—»ğ—² ğ—¼ ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ğ—¼\n-Informe como deseja receber a resposta (ex.: \"Apresente em formato de diagrama\").\nDica: ForneÃ§a sempre um contexto claro para que suas necessidades ficam claras.\nPS: Utilize IA nesse caso como um apoio, mas nÃ£o deixe de revisar e ajustar as saÃ­das para garantir a precisÃ£o e nÃ£o prejudicar seu trabalho.\nO que mais podemos fazer?\nCompartilhe e ajude sua rede!",
    "image_path": "linkedin_images/post_image_31.jpg"
  },
  {
    "author": "Lucas Assirati",
    "description": "Dica de python/pandas ğŸ¼: mask()\nO mÃ©todo mask() do pandas Ã© usado para substituir valores em um DataFrame onde uma condiÃ§Ã£o Ã© verdadeira. Ã‰ uma ferramenta bastante Ãºtil para manipular ou limpar dados de forma condicional.\nNo exemplo 1 temos um DataFrame com trÃªs colunas contendo nÃºmeros de 1 atÃ© 500. Ao utilizar o mÃ©todo df.mask(df < 30), estamos solicitando que os valores menores que 30 no dataframe df original sejam substituÃ­dos por NaN no dataframe df_com_mascara destino.\nJÃ¡ no exemplo 2, temos uma passagem de parÃ¢metro adicional: df.mask(df < 30, -1). Dessa forma, solicitamos que os valores menores que 30 no dataframe df original sejam substituÃ­dos por -1 no dataframe df_com_mascara destino, pois foi pedido via passagem de parÃ¢metro, um valor especÃ­fico para a troca.\nPode-se citar como aplicaÃ§Ãµes prÃ¡ticas para o mÃ©todo:\n- Limpeza de dados, substituindo valores invÃ¡lidos ou indesejados por NaN ou outros valores;\n- PrÃ©-processamento, preparando dados para anÃ¡lises ao substituir valores que atendem a certas condiÃ§Ãµes;\n- AnÃ¡lises condicionais, ao modificar dados com base em condiÃ§Ãµes especÃ­ficas para anÃ¡lises mais aprofundadas;\ndentre tantas outras alternativas, dependendo do contexto e do projeto a ser aplicado.\nhashtag\n#\npython\nhashtag\n#\npandas\nhashtag\n#\nmask\nhashtag\n#\ndataframe\nhashtag\n#\nfiltro\nhashtag\n#\nfilter\nhashtag\n#\nreplace",
    "image_path": "linkedin_images/post_image_32.jpg"
  },
  {
    "author": "Rodrigo Santana",
    "description": "Se eu fosse Analista de Dados e quisesse migrar para Engenharia de Dados em 2025 eu seguiria essa trilhaâ€¦\nSempre re-escrevo esse post, e sempre mudo algo..\nOs conceitos e fundamentos se mantÃªm, mas Ã© interessante como as percepÃ§Ãµes mudam.\nğŸ’¡ Conceitos e Fundamentos:\n- Arquitetura de dados: Conceitos sobre Data Warehouse, Data Lake, Data Lakehouse e Data Marts.\n- Modelagem de Dados: Conceitos sobre Star Schema, Snowflake Schema, Data Vault. Aqui eu focaria em entender as principais diferenÃ§as entre os modelos. Vantagens e Desvantagens\nArquitetura MedalhÃ£o: bronze, silver, gold.\n- Processamento distribuÃ­do: Estudaria sobre processamento distribuÃ­do com Spark. Eu iria focar em Spark e leria um livro sobre, um bom livro jÃ¡ cobre os conceitos e a prÃ¡tica de um framework tÃ£o usado. O meu foco estaria nele, sei que existem outros mas na minha opiniÃ£o se dominar bem spark estÃ¡ Ã³timo.\nArmazenamento de dados: Estudaria sobre formatos: parquet, json, delta, iceberg. O objetivo Ã© entender o bÃ¡sico mesmo, por exemplo: Porque armazenar dados em parquet Ã© interessante para cloud?\nğŸ’¡ Trabalhando com API's:\nTodo Engenheiro(a) de dados trabalha ou trabalharÃ¡ com API 's. EntÃ£o Ã© importante aprender sobre:\n- Como consumir API's.\n- MÃ©todos de autenticaÃ§Ã£o.\n- Como funciona basicamente, entender sobre rate limit, backfilling, webhooks.\n- Threading\nğŸ’¡ OrquestraÃ§Ã£o de Dados\nEstudaria o principal produto para orquestragem hoje no mercado que Ã© o Apache Airflow.\nEntenderia como esse software funciona, boas prÃ¡ticas para criaÃ§Ã£o de DAG's, como funciona recursos e principais integraÃ§Ãµes.\nğŸ’¡ SoluÃ§Ãµes Modernas (modern data stack)\nEstudaria algumas ferramentas muito faladas ultimamente para compor stacks de dados.\nNÃ£o precisa ficar especialista nelas. As inclua no seu projeto de desenvolvimento de estudos e pronto.\nSÃ£o elas:\n- airbyte\n- dbt\n- datahub\n- airflow + dbt\n- duckdb\nVocÃª nÃ£o precisa ficar expert em todas, Ã© importante entender onde cada uma se encaixa, quando usar e como usar.\nğŸ’¡Cloud\nEscolha uma das trÃªs mais usadas: AWS, Azure e GCP.\n(Eu iria de AWS ğŸ˜€ )\nEscolha uma delas e aprenda os produtos de dados que sÃ£o mais usados.\nPense: como fazer um projeto bÃ¡sico na AWS?\nExemplo: Assumindo uma APi pÃºblica, como posso subir um cÃ³digo python para consumir uma API, escrever no Data Lake, modelar as tabelas e inserir em um Data Warehouse usando 100% a AWS?\nBom, esse foi um caminho que eu seguiria para migrar de Analista de Dados para Engenheiro de Dados..\nSei que faltou algumas ferramentas ou habilidades na lista, mas tentei considerar que hoje um Analista de Dados jÃ¡ domina e atua com muita coisa..\nEntÃ£o, na minha opiniÃ£o, jÃ¡ tem um bom background, sÃ³ precisa focar no que pode completar mesmo.\nFaz sentido para vocÃª?\nComenta aqui.\nAproveite e envie para um Analista de Dados que estÃ¡ buscando essa migraÃ§Ã£o.\nhashtag\n#\ndataengineering",
    "image_path": "linkedin_images/post_image_33.jpg"
  },
  {
    "author": "Bruno Azambuja",
    "description": "ğŸš€ Gere anÃ¡lises em seu dataframe via Chat com a biblioteca Vanna!\nVanna transforma questÃµes de linguagem natural em anÃ¡lises detalhadas com uso de SQL.\nVanna Ã© uma estrutura Python RAG (Retrieval-Augmented Generation) de cÃ³digo aberto licenciada pelo MIT para geraÃ§Ã£o de SQL e funcionalidades relacionadas.\nPara mais informaÃ§Ãµes dessa biblioteca acesse:\nhttps://lnkd.in/dKscdm3A\nhashtag\n#\ndatascience\nhashtag\n#\nmachinelearning\nhashtag\n#\nvanna",
    "image_path": "linkedin_images/post_image_34.jpg"
  },
  {
    "author": "Bruno Azambuja",
    "description": "Lux Ã© uma biblioteca Python projetada para simplificar e acelerar o processo de exploraÃ§Ã£o de dados. Ele faz isso sugerindo visualizaÃ§Ãµes e insights quando vocÃª exibe um dataframe em um Jupyter Notebook.\nEssas visualizaÃ§Ãµes ajudam a descobrir tendÃªncias e padrÃµes interessantes em seus dados, e sÃ£o apresentadas em um widget interativo, permitindo que vocÃª explore e compreenda facilmente seu conjunto de dados, mesmo ao lidar com grandes quantidades de dados.\nLink para saber mais e experimentar -\nhttps://lnkd.in/dxiN6GtF\nhashtag\n#\ntechnology\nhashtag\n#\nartificialintelligence\nhashtag\n#\nmachinelearning\nhashtag\n#\nprogramming\nhashtag\n#\ndatascience",
    "image_path": "linkedin_images/post_image_35.jpg"
  },
  {
    "author": "Heitor Sasaki",
    "description": "Tu jÃ¡ deve tÃ¡ cansado de ver esse grÃ¡fico.\nÃ‰ sempre a mesma coisa:\nA anÃ¡lise descritiva sÃ£o os analistas...\nA anÃ¡lise preditiva e prescritiva sÃ£o os cientistas\nblablubla.\nNÃ£o me leve a mal, Ã© bom saber isso.\nMas eu quero ir alÃ©m e interpretar o grÃ¡fico de outra maneira.\nConectar esse conhecimento com gestÃ£o de mudanÃ§as e cultura data driven.\nNa newsletter de amanhÃ£, vou falar mais sobre isso e resumir o que falamos hoje na call do Data Creators.\nInscreva-se para nÃ£o perder.\nheitorsasaki.substack.com",
    "image_path": "linkedin_images/post_image_36.jpg"
  },
  {
    "author": "Raiane Rosa",
    "description": "ğŸš€ Melhore suas fÃ³rmulas DAX no Power BI com o uso de variÃ¡veis\nÃ€ medida que avanÃ§amos no aprendizado da Linguagem DAX, Ã© sempre bom que estejamos atentos na otimizaÃ§Ã£o de nossas fÃ³rmulas para melhorar a legibilidade e o desempenho da ferramenta. Para isso, podemos utilizar variÃ¡veis (var), o que torna nossas fÃ³rmulas mais claras e facilita a manutenÃ§Ã£o.\nğŸ’¡Exemplo PrÃ¡tico:\nSuponha que vocÃª queira saber a porcentagem de meses que atingiram a meta de faturamento mensal de $200 milhÃµes. Com variÃ¡veis, sua fÃ³rmula ficaria assim:\n% Meses Bateram Meta =\nvar MetaFaturamentoMensal = 200000000\nvar qtdTotalMeses = DISTINCTCOUNT('CalendÃ¡rio'[InÃ­cio do MÃªs])\nvar qtdMesesBateramMeta = COUNTROWS(\nFILTER(\nVALUES('CalendÃ¡rio'[InÃ­cio do MÃªs]),\n[Faturamento Total] >= MetaFaturamentoMensal\n)\n)\nreturn\nDIVIDE(qtdMesesBateramMeta,qtdTotalMeses)\nğŸš« Exemplo sem variÃ¡veis:\n% Meses Bateram Meta = DIVIDE(COUNTROWS(FILTER(VALUES('CalendÃ¡rio'[InÃ­cio do MÃªs]),[Faturamento Total]>=200000000)),DISTINCTCOUNT('CalendÃ¡rio'[InÃ­cio do MÃªs]))\nComo vocÃª pode notar, o uso de variÃ¡veis facilita a organizaÃ§Ã£o e entendimento da fÃ³rmula. AlÃ©m disso, como efeito colateral, ainda Ã© capaz de melhorar o desempenho do modelo ao evitar cÃ¡lculosÂ repetidos.\nhashtag\n#\nPowerBI\nhashtag\n#\nDataAnalytics\nhashtag\n#\nBusinessIntelligence\nhashtag\n#\nAnÃ¡lisedeDados\nhashtag\n#\nLinguagemDAX\nhashtag\n#\nVariÃ¡veis",
    "image_path": "linkedin_images/post_image_37.jpg"
  },
  {
    "author": "Wilson Franquilino",
    "description": "Bora entender....\nEmbora o DAX e o SQL tenham sintaxes e finalidades diferentes, muitas operaÃ§Ãµes podem ser realizadas de maneira semelhante em ambas as linguagens. Compreender como traduzir essas funÃ§Ãµes entre DAX e SQL pode ajudar a maximizar o uso de ambas as ferramentas para anÃ¡lises de dados mais eficazes.",
    "image_path": "linkedin_images/post_image_38.jpg"
  },
  {
    "author": "Ronnan Lima",
    "description": "Fala pessoal, tudo bom? boa sexta e fiquem com um belo post sobre o Training Day!\nSC-900: 18/06/2024, 10:00 â€“ 14:00 | 19/06/2024, 10:00 â€“ 13:15\nhttps://lnkd.in/dfmY6uN2\nDP-900: 01/07/2024, 10:00 â€“ 13:00 | 02/07/2024, 10:00 â€“ 12:15\nhttps://lnkd.in/d_279mUd\nAZ-900: 16/07/2024, 10:00 â€“ 12:30 | 17/07/2024, 10:00 â€“ 13:00\nhttps://lnkd.in/dNthKA5d\nSC-900: 23/07/2024, 10:00 â€“ 14:00 | 24/07/2024, 10:00 â€“ 13:15\nhttps://lnkd.in/dFymnZAp\nEspero que gostem e compartilhem com os colegas que estÃ£o procurando conteÃºdo para estudar!\nGosta do meu conteÃºdo aqui? TambÃ©m estou em outras redes @ronnanlimadataeng :)\nhashtag\n#\ndataengineering\nhashtag\n#\nazure\nhashtag\n#\ndatascience\nhashtag\n#\npython\nhashtag\n#\nsql\nhashtag\n#\ncloud\nhashtag\n#\ndatabricks\nhashtag\n#\ndataanalytics\nhashtag\n#\nengenhariadedados\nhashtag\n#\ncienciadedados\nhashtag\n#\nnuvem\nhashtag\n#\nanalisededados",
    "image_path": "linkedin_images/post_image_39.jpg"
  },
  {
    "author": "Riviane Donha",
    "description": "RegressÃ£o de Aumento de Gradiente (GBR)\nA GBR vai alÃ©m de um simples conjunto de modelos, operando como um algoritmo adaptÃ¡vel que aprende com os dados.\nA chave reside na capacidade de aprender com os erros dos modelos anteriores. Cada novo modelo Ã© treinado para corrigir os erros do anterior, refinando as previsÃµes de forma iterativa.\nA GBR se destaca em diversas Ã¡reas desafiadoras, como:\nVisÃ£o Computacional: Reconhecimento de objetos, detecÃ§Ã£o de anomalias e anÃ¡lise de imagens mÃ©dicas.\nProcessamento de Linguagem Natural: AnÃ¡lise de sentimento, classificaÃ§Ã£o de texto e extraÃ§Ã£o de informaÃ§Ãµes.\nFinanÃ§as: PrevisÃ£o de fraudes, anÃ¡lise de risco e detecÃ§Ã£o de padrÃµes de mercado.\nSazonalidade em Vendas: PrevisÃ£o da demanda, otimizaÃ§Ã£o de estoques e planejamento de campanhas de marketing.\nRobustez: A GBR Ã© robusta a outliers e dados faltantes, tornando-a ideal para problemas do mundo real.\nConjunto de Mil Modelos: A GBR combina atÃ© mil modelos de TD em sÃ©rie, como mil especialistas trabalhando juntos, para alcanÃ§ar a melhor previsÃ£o possÃ­vel.\nSequÃªncia de Refinamento: A cada novo modelo, os erros do anterior sÃ£o utilizados para refinamento, como um time que se aprimora a cada desafio.",
    "image_path": "linkedin_images/post_image_40.jpg"
  },
  {
    "author": "Luana Carvalho",
    "description": "Amigos gravei esse vÃ­deo com muito carinho e temor!\nEu sempre levantarei a bandeira para usarmos a IA, nÃ£o Ã© atoa que tenho dedicado TODOS OS DIAS da minha vida a estudar e trabalhar com isso.\nO meu sustento depende disso, os meus sonhos serÃ£o realizados atravÃ©s do uso da IA, entÃ£o Ã© com muito temor e verdade que gravei esse vÃ­deo abaixo.\nLembrando que IA vai muuuuuito alÃ©m do ChatGPT mas isso Ã© sÃ³ a pontinha do Iceberg.\nEu enquanto profissional dedicada que sou a essa Ã¡rea me sinto no dever de falar e me encontro em meu lugar de fala se tratando disso.\nPor favor, assistam tudo e deixem as suas opniÃµes sobre, sÃ³ lembrem de me respeitar em quanto pessoa e profissional quando as suas opniÃµes forem divergentes das minhas.\nE pensem sempre na questÃ£o Ã©tica e moral quando estiverem imersivos nesse universo.\nAvisos:\nğŸ“š  Se vocÃª tem interesse em adquirir um E-book sobre dados feito por mim, preencha esse formulÃ¡rio que sÃ³ receberÃ¡ respostas atÃ© hoje, com as suas respostas vou poder direcionar o meu tempo e conhecimento para um conteÃºdo que realmente faÃ§a sentido para vocÃª consumir. Preencha aqui\nhttps://lnkd.in/dScagvnb\nâœˆ AmanhÃ£ estarei viajando para SP para um evento na sede do LinkedIn Brasil â™¥ e se vocÃª quiser ver tudoooo o que vou viver lÃ¡, acompanhe os meus story's em meu perfil pessoal no Instagram @iluanacarvalho\nhashtag\n#\ninteligenciaartificial\nhashtag\n#\nchatgpt\nhashtag\n#\nBoletimTech\nhashtag\n#\nLinkedInNotÃ­cias",
    "image_path": "linkedin_images/post_image_41.jpg"
  },
  {
    "author": "Karison Avelar",
    "description": "Super dica: 21 comandos mais usados em SQL e sua equivalÃªncia em DAX do Power BI\nAprender DAX pode ser um desafio, mas vocÃª pode usar seu conhecimento em SQL:\nSELECT -> EVALUATE\nFROM -> RELATED\nWHERE -> FILTER\nORDER BY -> SORT\nGROUP BY -> SUMMARIZE\nHAVING -> CALCULATE\nDISTINCT -> DISTINCT\nIS NULL -> ISBLANK\nIS NOT NULL -> NOT ISBLANK\nCOUNT -> COUNTROWS\nBETWEEN -> BETWEEN\nAVG ->AVERAGEX\nLIKE -> CONTAINS\nSUM -> SUMX\nMAX -> MAX\nMIN ->MIN\nAND -> &&\nOR -> OR\nNOT -> !\nIN -> IN\nPS: Nem todos os casos Ã© uma equivalÃªncia perfeita, mas sim uma lÃ³gica.\nCrÃ©dito:\nFÃ¡bio MarÃ§olia",
    "image_path": "linkedin_images/post_image_42.jpg"
  },
  {
    "author": "Ronnan Lima",
    "description": "Azure para Analistas de Dados: Seu roteiro para dominar esta stack!\nExame PL-300 - Analista de Dados do Microsoft Power BI\nâœ”ï¸PrÃ©-requisitos: vocÃª deve apresentar insights acionÃ¡veis trabalhando com os dados disponÃ­veis e aplicando a experiÃªncia no domÃ­nio.\nâœ”ï¸DuraÃ§Ã£o do Exame: 120 minutos\nâœ”ï¸NÃºmero de questÃµes: 40-60\nâœ”ï¸Nota mÃ­nima: 700\nâœ”ï¸Custo do Exame: $100\nğŸ“šRoteiro de estudos:\nhttps://lnkd.in/d2mDViAB\nğŸ“šSimulado Oficial:\nhttps://lnkd.in/d3ExfSbD\nExame DP-900 - Microsoft Azure Data Fundamentals\nâœ”ï¸PrÃ©-requisitos: Familiaridade com os conceitos de dados relacionais e nÃ£o relacionais.\nâœ”ï¸DuraÃ§Ã£o do Exame: 60 minutos\nâœ”ï¸NÃºmero de questÃµes: 40-60\nâœ”ï¸Nota mÃ­nima: 700\nâœ”ï¸Custo do Exame: $60\nğŸ“šRoteiro de estudos:\nhttps://lnkd.in/dWKXzBpp\nğŸ“šSimulado:\nhttps://lnkd.in/dnj-9rsC\nExame AZ-900 - Microsoft Azure Fundamentals\nâœ”ï¸PrÃ©-requisitos: Familiaridade com componentes arquitetÃ´nicos do Azure e serviÃ§os do Azure, como computaÃ§Ã£o, rede e armazenamento.\nâœ”ï¸DuraÃ§Ã£o do Exame: 60 minutos\nâœ”ï¸NÃºmero de questÃµes: 40-60\nâœ”ï¸Nota mÃ­nima: 700\nâœ”ï¸Custo do Exame: $60\nğŸ“šRoteiro de estudos:\nhttps://lnkd.in/dsCB_WrX\nğŸ“šSimulado:\nhttps://lnkd.in/ddfPavCz\nGostou da dica? Compartilhe!\nTambÃ©m estou em outras redes:\nhttps://lnkd.in/dBtT2BVF\n*Sobre os simulados, lembrando que antes sÃ³ existiam questÃµes em inglÃªs agora elas jÃ¡ estÃ£o traduzidas.\nhashtag\n#\nazure\nhashtag\n#\ndatascience\nhashtag\n#\npython\nhashtag\n#\nsql\nhashtag\n#\ncloud\nhashtag\n#\nanalytics\nhashtag\n#\ndatabricks\nhashtag\n#\ndataanalytics\nhashtag\n#\ndataarchitect\nhashtag\n#\ndataengineering\nhashtag\n#\nai",
    "image_path": "linkedin_images/post_image_43.jpg"
  },
  {
    "author": "LetÃ­cia Smirelli",
    "description": "Ao desenvolver relatÃ³rios no Power BI Ã© importante levar em conta as necessidades e experiÃªncia dos usuÃ¡rios. No post de hoje vocÃª vai aprender diversos recursos que podem contribuir para a acessibilidade dos seus projetos, como: paleta de cores, temas de alto contraste, texto alternativo, marcadores e outros! ğŸ¨\nConhece alguma outra dica ou recurso para relatÃ³rios mais acessÃ­veis? Contribua nos comentÃ¡rios! ğŸ§™â€â™‚ï¸ğŸ˜‰\n--\nhashtag\n#\npowerbi\nhashtag\n#\nmicrosoftpowerbi\nhashtag\n#\nbusinessinteligence\nhashtag\n#\ndataanalytics\nhashtag\n#\ndatascience\nhashtag\n#\ndatastorytelling\nhashtag\n#\ndashboards\nhashtag\n#\ndashboardpowerbi\nhashtag\n#\ndashboards\nhashtag\n#\nexcel\nhashtag\n#\npowerplatform\nhashtag\n#\nacessibilidade",
    "image_path": "linkedin_images/post_image_44.jpg"
  },
  {
    "author": "Luciano Santos",
    "description": "Sua empresa deixa o lÃ­der fazer gestÃ£o?\nOutro dia um gestor me disse que nÃ£o tinha tempo de fazer 1:1s com o time, por todas as outras tarefas que eram demandadas dele. Pedi para ele me listar as tarefas que eram mais importantes do que cuidar do \"bem\" mais importante da empresa: as pessoas.\nSilÃªncio.\nLÃ­deres e empresas: nÃ£o existe NADA mais importante do que a lideranÃ§a focar nas pessoas. Nada. Tudo comeÃ§a por ali, o resto vem depois.\nFala genial do\nAlÃª Prates\n(sigam esse cara!)\nDe novo: sua empresa deixa o lÃ­der fazer gestÃ£o?\nhashtag\n#\nlideranÃ§a\nhashtag\n#\ngestÃ£o\nhashtag\n#\npessoas\nhashtag\n#\nrh",
    "image_path": "linkedin_images/post_image_45.jpg"
  },
  {
    "author": "Filipe Spadetto",
    "description": "VocÃª gostaria de praticar PySpark e Databricks? Se vocÃª nÃ£o sabe existe a versÃ£o gratuita do Databricks chamada Databricks Community. Utilizando o notebook e alguns comandos vocÃª consegue diversos datasets para anÃ¡lise e tratamento de dados para praticar. Ã‰ sÃ³ utilizar o comando para achar uma lista enorme de datasets:\ndisplay(\ndbutils.fs.ls\n(\"/databricks-datasets\"))\nGostou? Bons estudos ğŸ˜",
    "image_path": "linkedin_images/post_image_46.jpg"
  },
  {
    "author": "Talles Victor",
    "description": "SQL fundamental em uma pÃ¡gina!\nSQL, ou Structured Query Language, Ã© uma linguagem de programaÃ§Ã£o projetada para gerenciar e manipular dados em sistemas de gerenciamento de banco de dados relacionais (RDBMS). Ã‰ uma linguagem padronizada e amplamente utilizada em bancos de dados relacionais, como MySQL, PostgreSQL, SQL Server, Oracle, SQLite, entre outros.\nSQL Ã© uma linguagem de alto nÃ­vel e declarativa, o que significa que os usuÃ¡rios podem especificar o que desejam obter, inserir, atualizar ou excluir dos dados, sem precisar se preocupar com os detalhes de como essas operaÃ§Ãµes sÃ£o realizadas internamente pelo sistema de banco de dados. Em vez disso, o sistema de banco de dados interpreta as instruÃ§Ãµes SQL e executa as operaÃ§Ãµes de forma eficiente para retornar os resultados desejados.\nAbaixo, os comandos fundamentais para que vocÃª possa avanÃ§ar seu conhecimento nessa linguagem.\nOBS: O texto foi escrito com a ajuda do ChatGPT\n-The grind never stops",
    "image_path": "linkedin_images/post_image_47.jpg"
  },
  {
    "author": "Fabio MarÃ§olia",
    "description": "Os 7 Principais Tipos de Banco de Dados e Quando usar cada um:\nğŸ’¡NÃ£o conhecer pode levar a decisÃµes erradas nas soluÃ§Ãµes, sendo difÃ­cil uma migraÃ§Ã£o depois.\nğŸ­-ğ—¥ğ—²ğ—¹ğ—®ğ—°ğ—¶ğ—¼ğ—»ğ—®ğ—¶ğ˜€ (ğ—¥ğ——ğ—•ğ— ğ—¦)\n-MySQL, PostgreSQL, Oracle Database, SQL Server\n-Uso: AplicaÃ§Ãµes empresariais que necessitam de transaÃ§Ãµes complexas e integridade de dados.\nğŸ®-ğ—¡ğ—¼ğ—¦ğ—¤ğ—Ÿ\n-MongoDB, Cassandra, Redis, Neo4j\n-Uso: Big Data e aplicaÃ§Ãµes em tempo real que necessitam de escalabilidade e flexibilidade.\nğŸ¯-ğ—–ğ—¼ğ—¹ğ˜‚ğ—»ğ—®ğ—¿ğ—²ğ˜€\n-Apache Cassandra, BigQuery\n-Uso: AnÃ¡lise de grandes volumes de dados, relatÃ³rios de business intelligence (BI) e data warehousing, onde a leitura rÃ¡pida de colunas especÃ­ficas de grandes tabelas Ã© necessÃ¡ria.\nğŸ°-ğ—¢ğ—Ÿğ—”ğ—£\n-DuckDB, Analysis Services\n-Uso: Caching e agregaÃ§Ãµes de dados possibilitando uma maior performance e consultas multidimensionais para BI.\nğŸ±-ğ—šğ—¿ğ—®ğ—³ğ—¼ğ˜€\n-Neo4j, ArangoDB\n-Uso: AnÃ¡lise de redes sociais, sistemas de recomendaÃ§Ã£o e detecÃ§Ã£o de fraudes.\nğŸ²-ğ—©ğ—²ğ˜ğ—¼ğ—¿ğ—¶ğ—®ğ—¶ğ˜€\n-Milvus, Faiss (desenvolvido pelo Facebook AI Research), Elasticsearch (com plugins ou extensÃµes para busca vetorial)\n-Uso: AplicaÃ§Ãµes de inteligÃªncia artificial e machine learning\nğŸ³-ğ——ğ—®ğ—±ğ—¼ğ˜€ ğ—±ğ—² ğ—¦ğ—²Ìğ—¿ğ—¶ğ—² ğ—§ğ—²ğ—ºğ—½ğ—¼ğ—¿ğ—®ğ—¹\n-InfluxDB, TimescaleDB\n-Uso: Monitoramento de sistemas, IoT e anÃ¡lise de sÃ©ries temporais.\nFaltou algum? O que acredita ser fundamental em conhecimento de banco de dados?\nCompartilhe para ajudar sua rede!",
    "image_path": "linkedin_images/post_image_48.jpg"
  },
  {
    "author": "ClÃ©nio Mutunda",
    "description": "ğŸ± ğ—§ğ—¢ğ—¡ğ—¦ PARA SUBSTITUIR O ğ—•ğ—¥ğ—”ğ—¡ğ—–ğ—¢ ğ—£ğ—¨ğ—¥ğ—¢ NAS SUAS INTERFACES!â¬œâœ¨\nO branco puro pode causar fadiga visual, especialmente em ambientes com muita luminosidade, o que gera desconforto e cansaÃ§o para os usuÃ¡rios, prejudicando a experiÃªncia e diminuindo o tempo de uso do teu produto digital. Por esse motivo, trouxe 5 alternativas que podem ser mais confortÃ¡veis para o usuÃ¡rio e um pouco mais elegantes que o clÃ¡ssico branco puro.\nAcompanhe o carrossel!ğŸ‘‡ğŸ¿\nhashtag\n#\nfff\nhashtag\n#\nuxdesign\nhashtag\n#\nacessibilidade\nhashtag\n#\ndesignconsciente\nhashtag\n#\nclenda",
    "image_path": "linkedin_images/post_image_49.jpg"
  },
  {
    "author": "Tajamul Khan",
    "description": "ğŸ¯ ğ—¦ğ—¤ğ—Ÿ ğ—­ğ—²ğ—¿ğ—¼ ğ˜ğ—¼ ğ—›ğ—²ğ—¿ğ—¼ Notes ğ˜„ğ—¶ğ˜ğ—µ ğ— ğ—¶ğ—»ğ—±ğ—ºğ—®ğ—½ ğŸ“š\nSQL, or Structured Query Language, is a language used to manage and manipulate relational databases.\nIt may not sound exciting, but its power and flexibility make it an indispensable tool for anyone working with data.\nâš¡ Whether you're a business owner trying to make sense of your sales data, a researcher analyzing large datasets, or a software developer building applications that rely on databases, SQL is the way to go.\nWith SQL, you can easily perform complex queries, filter and sort data, and aggregate information to gain insights that would be impossible to obtain manually.\nAnd because SQL is a standardized language, you can use it with virtually any database system, from MySQL and PostgreSQL to Oracle and SQL Server.\nBut don't just take my word for it. Consider the following examples:\nğŸ‡ A small business owner uses SQL to analyze customer data and identify trends that help them make informed decisions about marketing and product development.\nğŸ‡ A researcher uses SQL to join and analyze multiple datasets, uncovering insights that lead to new discoveries and innovations.\nğŸ‡ A software developer uses SQL to build a web application that requires real-time access to a large database, ensuring that users receive accurate and up-to-date information.\nAs you can see, SQL is a versatile and powerful tool that can help you achieve your goals, no matter what they may be. So why not give it a try and see what insights you can uncover? With SQL, the possibilities are endless!\nâœ¨ Follow\nTajamul Khan\nfor more!\nhashtag\n#\nsql\nhashtag\n#\ncommands\nhashtag\n#\ndatabase\nhashtag\n#\nsqldeveloper\nhashtag\n#\nsqlqueries\nhashtag\n#\ndatabasequeries\nhashtag\n#\nsqlprogramming\nhashtag\n#\ndeveloper\nhashtag\n#\nprogrammer\nhashtag\n#\nfunctions\nhashtag\n#\ndataanalytics\nhashtag\n#\ndataanalyst\nhashtag\n#\ndataanalysis\nhashtag\n#\ndata\nhashtag\n#\nprogramming\nhashtag\n#\nlanguage\nhashtag\n#\nsoftwaredeveloper\nhashtag\n#\ndevelopment\nhashtag\n#\nmysql\nhashtag\n#\noracle\nhashtag\n#\nbusiness\nhashtag\n#\nartificialintelligence\nhashtag\n#\nmachinelearning\nhashtag\n#\ntechnology\nhashtag\n#\nai\nhashtag\n#\nml\nhashtag\n#\ndatascience",
    "image_path": "linkedin_images/post_image_50.jpg"
  },
  {
    "author": "Mohibul Alam",
    "description": "ğŸ¯ ğ—¦ğ—¤ğ—Ÿ ğ—­ğ—²ğ—¿ğ—¼ ğ˜ğ—¼ ğ—›ğ—²ğ—¿ğ—¼ Exclusive Hand NotesğŸ“š\nğŸ‘‰ SQL, or Structured Query Language, is a language used to manage and manipulate relational databases. It may not sound exciting, but its power and flexibility make it an indispensable tool for anyone working with data.\nâš¡ Whether you're a business owner trying to make sense of your sales data, a researcher analyzing large datasets or a software developer building applications that rely on databases, SQL is the way to go.\nğŸ‘‰With SQL, you can easily perform complex queries, filter and sort data and aggregate information to gain insights that would be impossible to obtain manually. And because SQL is a standardized language, you can use it with virtually any database system, from MySQL and PostgreSQL to Oracle and SQL Server.\nâš¡ But don't just take my word for it. Consider the following examples:\nğŸ‡ A small business owner uses SQL to analyze customer data and identify trends that help them make informed decisions about marketing and product development.\nğŸ‡ A researcher uses SQL to join and analyze multiple datasets, uncovering insights that lead to new discoveries and innovations.\nğŸ‡ A software developer uses SQL to build a web application that requires real-time access to a large database, ensuring that users receive accurate and up-to-date information.\nAs you can see, SQL is a versatile and powerful tool that can help you achieve your goals, no matter what they may be. So why not give it a try and see what insights you can uncover? With SQL, the possibilities are endless!\nğŸ”¥ you can learn SQL from\nMOHNAS\nW3Schools.com\nğŸ”” Follow\nMohibul Alam\nto learn new things everyday ğŸ’¡\nhashtag\n#\ndevelopment\nhashtag\n#\nmarketing\nhashtag\n#\nbusiness\nhashtag\n#\ndata\nhashtag\n#\nsales\nhashtag\n#\nsoftwaredeveloper\nhashtag\n#\nhelp\nhashtag\n#\nsmallbusiness\nhashtag\n#\npower\nhashtag\n#\nbuilding\nhashtag\n#\nsql\nhashtag\n#\nmysql\nhashtag\n#\ndatabase\nhashtag\n#\nlanguage\nhashtag\n#\noracle",
    "image_path": "linkedin_images/post_image_51.jpg"
  },
  {
    "author": "DiÃªgo Oliveira",
    "description": "Acabei de concluir o curso â€œFundamentos de AnÃ¡lise de Dadosâ€!",
    "image_path": "linkedin_images/post_image_52.jpg"
  },
  {
    "author": "DiÃªgo Oliveira",
    "description": "Acabei de concluir  o curso â€œFundamentos de EstatÃ­stica: Parte 1â€ de\nEddie Davila\n! Confira em:\nhttps://lnkd.in/gDQ4J7Yq\nhashtag\n#\nestatÃ­stica\n.",
    "image_path": null
  },
  {
    "author": "Gustavo Caetano",
    "description": "Pra galera que estÃ¡ aprendendo a codar ou acabou de iniciar na Ã¡rea de T.I trouxe aqui essas dicas de pontos para ajudar vocÃªs no dia a dia de cÃ³digos e tambÃ©m algumas para acrescentar no dia a dia do inglÃªs.\nComentem aqui o que acharam dessas dicas.",
    "image_path": null
  },
  {
    "author": "DiÃªgo Oliveira",
    "description": "Gostaria de compartilhar que finalizei meu curso de Bacharelado em sistemas de informaÃ§Ã£o na instituiÃ§Ã£o de ensino UniFTC.",
    "image_path": null
  },
  {
    "author": "DiÃªgo Oliveira",
    "description": "Acabei de concluir  o curso â€œQuarta RevoluÃ§Ã£o Industrial: Desafios da ComputaÃ§Ã£o em Nuvemâ€ de David Carrasco LÃ³pez! Confira em:\nhttps://lnkd.in/djpp_fxU\nhashtag\n#\nindÃºstria40\nhashtag\n#\ncomputaÃ§Ã£oemnuvem\n.",
    "image_path": null
  },
  {
    "author": "DiÃªgo Oliveira",
    "description": "Gostaria de compartilhar que recebi uma nova certificaÃ§Ã£o: Apache Airflow na PrÃ¡tica: Do ZERO ao DEPLOY, com Python! da empresa\nUdemy Brasil\n!",
    "image_path": null
  },
  {
    "author": "VÃ¢nia Paula",
    "description": "Tire todas suas dÃºvidas de gramÃ¡tica em:\nhttps://lnkd.in/e-jFHmwC",
    "image_path": null
  },
  {
    "author": "Sandeep Jain",
    "description": "Imposter Syndrome affects as many as 58% of tech employees. It prevents people from performing their best by reducing their confidence in their own abilities.\nhashtag\n#\nimpostersyndrome\nhashtag\n#\ntechcareer\nhashtag\n#\ndevelopercommunity\nhashtag\n#\nsoftwareengineer\nhashtag\n#\nmentalhealth",
    "image_path": "linkedin_images/post_image_59.jpg"
  },
  {
    "author": "Rodrigo Braz",
    "description": "Boa noite pessoal,\nVocÃªs sabem o que Ã© OKR ?\nAbaixo elaborei um artigo para explicar um pouco essa metodologia,  que vem sendo utilizadas cada vez mais nas organizaÃµes;\nVale a pena conferir !\nhashtag\n#\nokrs\nhashtag\n#\nagilidade\nhashtag\n#\ncompartilharconhecimento\nhashtag\n#\ndesenvolvimento",
    "image_path": "linkedin_images/post_image_60.jpg"
  },
  {
    "author": "DataV",
    "description": "Colinha de SQL / SQL Cheat Sheet\nComeÃ§ou a estudar a SQL?\nQue tal uma colinha para relembrar os comandos.\nVia:\nOdemir Depieri Jr\nComunidade de dados no Telegram:\nhttps://lnkd.in/duveBsTr\nAjuste no material identificado pela comunidade:\n1Âº coluna dos comandos:\n1) Criar base de dados\n[ CREATE DATABASE MinhaBase; ]\n2) Criando uma tabela\n[ CREATE TABLE NomeTabela ( Coluna1 int, Coluna2 varchar ) ]\n3) Deletar uma tabela\n[ DROP TABLE NomeTabela ]\n4) Atualizar uma tabela\n[ UPDATE NomeTabela; SET Coluna1 = 100; WHERE Coluna2 = 'AlgumValor' ]\nhashtag\n#\ncienciadedados",
    "image_path": "linkedin_images/post_image_61.jpg"
  }
]